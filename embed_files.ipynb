{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b78ef96-cdc6-4074-b28a-b1fe1425c4fb",
   "metadata": {},
   "source": [
    "# Create Audio Embeddings\n",
    "\n",
    "This notebook demonstrates how to generate embeddings for audio files using BirdNET (Kahl et al., 2023), a pretrained model available in the [bioacoustics model zoo](https://github.com/kitzeslab/bioacoustics-model-zoo).\n",
    "\n",
    "**Notebook Overview:**\n",
    "1. **Setup:** Define directories and load required libraries.\n",
    "2. **Model Loading:** Load the BirdNET model.\n",
    "3. **File Collection:** Get sample `.wav` files from the specified data folder.\n",
    "4. **Embedding Generation:** For each file, generate embeddings and save them as a CSV file.\n",
    "5. **Results:** Summarize and display processing information.\n",
    "\n",
    "_This demo is simplified from the script used in the related study to run on a small number of sample files._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cc2a57-7e61-4979-8909-2b6bb645bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import bioacoustics_model_zoo as bmz\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a987b1-33f0-49b6-b4d5-b9524844d093",
   "metadata": {},
   "source": [
    "## Set up directories\n",
    "\n",
    "We define the location of our input audio files (sample_audio) and create a directory\n",
    "for saving the resulting embedding CSV files (sample_embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38669ba8-0980-4f68-9588-41e16b2fe295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory for sample audio files\n",
    "data_root = Path(\"sample_audio\")\n",
    "\n",
    "# Set and, if needed, create the output directory for embedding CSV files\n",
    "emb_save_dir = Path(\"sample_embeddings\")\n",
    "emb_save_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b332ad7e-be87-4bcc-903b-cc532b2d0ef5",
   "metadata": {},
   "source": [
    "## Load the model\n",
    "\n",
    "We load BirdNET from the bioacoustics model zoo.\n",
    "This model will be used to generate embeddings from our audio files.\n",
    "\n",
    "Note that loading BirdNET will raise warnings and download files needed for it to work into your working directory; this is normal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f53d4464-bcac-4265-9554-da8e8ce2361f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded completed: BirdNET_GLOBAL_6K_V2.4_Labels_af.txt\n",
      "downloading model from URL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sash/miniforge3/envs/ops11-tf/lib/python3.10/site-packages/opensoundscape/ml/cnn.py:621: UserWarning: \n",
      "                    This architecture is not listed in opensoundscape.ml.cnn_architectures.ARCH_DICT.\n",
      "                    It will not be available for loading after saving the model with .save() (unless using pickle=True). \n",
      "                    To make it re-loadable, define a function that generates the architecture from arguments: (n_classes, n_channels) \n",
      "                    then use opensoundscape.ml.cnn_architectures.register_architecture() to register the generating function.\n",
      "\n",
      "                    The function can also set the returned object's .constructor_name to the registered string key in ARCH_DICT\n",
      "                    to avoid this warning and ensure it is reloaded correctly by opensoundscape.ml.load_model().\n",
      "\n",
      "                    See opensoundscape.ml.cnn_architectures module for examples of constructor functions\n",
      "                    \n",
      "  warnings.warn(\n",
      "/Users/sash/miniforge3/envs/ops11-tf/lib/python3.10/site-packages/opensoundscape/ml/cnn.py:645: UserWarning: Failed to detect expected # input channels of this architecture.Make sure your architecture expects the number of channels equal to `channels` argument 1). Pytorch architectures generally expect 3 channels by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded completed: BirdNET_GLOBAL_6K_V2.4_Model_FP16.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sash/miniforge3/envs/ops11-tf/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "/Users/sash/miniforge3/envs/ops11-tf/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:465: UserWarning: Warning: Enabling `experimental_preserve_all_tensors` with the BUILTIN or AUTO op resolver is intended for debugging purposes only. Be aware that this can significantly increase memory usage by storing all intermediate tensors. If you encounter memory problems or are not actively debugging, consider disabling this option.\n",
      "  warnings.warn(\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Load the BirdNET model (this may take a few moments if not already cached)\n",
    "model = bmz.BirdNET()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2c415f-9a2a-4312-b789-76bcdbae6ed5",
   "metadata": {},
   "source": [
    "## Gather Input Files\n",
    "\n",
    "We search for audio files with the extension `.wav` within the indicated sample folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d07eb554-b2fb-4ba0-a70b-85c51ebf69e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 files to embed.\n",
      "Embeddings will be saved to: sample_embeddings/\n"
     ]
    }
   ],
   "source": [
    "# Get a list of input .wav files\n",
    "input_files = list(data_root.glob(\"*.wav\"))\n",
    "print(f\"Found {len(input_files)} files to embed.\")\n",
    "print(f\"Embeddings will be saved to: {emb_save_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb4f223-425c-4dc0-9d2a-0da951a8c7b6",
   "metadata": {},
   "source": [
    "## Generate Feature Embeddings\n",
    "\n",
    "This function:\n",
    "- Determines an output CSV filename (saved in `sample_embeddings`).\n",
    "- Uses BirdNET to generate embeddings.\n",
    "- Saves the embeddings to disk, in our case reducing precision to float16.\n",
    "\n",
    "Errors are returned for logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ae61669-8608-484c-923a-faa57d40fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(file_path):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a single audio file and save the result as a CSV.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (Path): Path to the audio file.\n",
    "    \n",
    "    Returns:\n",
    "        tuple (file_path, status): where status is \"Success\" or an Exception instance.\n",
    "    \"\"\"\n",
    "    file_path = Path(file_path)\n",
    "    # Build the output filename directly under the emb_save_dir (no nested folders)\n",
    "    dest = emb_save_dir / f\"{file_path.stem}_embeddings.csv\"\n",
    "\n",
    "    try:\n",
    "        # Generate embeddings (passing a single file as a list)\n",
    "        embeddings = model.embed([str(file_path)], batch_size=64, num_workers=1)\n",
    "        # Convert columns to float16 format for smaller file size\n",
    "        for col in embeddings.columns:\n",
    "            embeddings[col] = embeddings[col].astype('float16')\n",
    "        # Save embedding DataFrame to CSV\n",
    "        embeddings.to_csv(dest)\n",
    "    except Exception as e:\n",
    "        return file_path, e\n",
    "\n",
    "    return file_path, \"Success\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400b9f1-f72b-4aa0-addf-e7064fe3fb7a",
   "metadata": {},
   "source": [
    "## Process Audio Files\n",
    "\n",
    "We loop over the files and embed each one, displaying a progress bar (`tqdm` required)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21a61fad-0d69-45cc-8c26-9a2d0cf54400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Audio Files:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b29bc9810bf4a2cbf25515b143d209c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sash/miniforge3/envs/ops11-tf/lib/python3.10/tempfile.py:833: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/var/folders/ct/flqdpp9573b3drcbvfhj15gr0000gn/T/tmpekgt2inm'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "Processing Audio Files:  33%|███▎      | 1/3 [00:12<00:25, 12.90s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9602ee55a59d44ea89dcb3ee69ff2a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sash/miniforge3/envs/ops11-tf/lib/python3.10/tempfile.py:833: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/var/folders/ct/flqdpp9573b3drcbvfhj15gr0000gn/T/tmppd6bht32'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "Processing Audio Files:  67%|██████▋   | 2/3 [00:25<00:12, 12.57s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669d52d1a58c429aaaa8354f0fdc158f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sash/miniforge3/envs/ops11-tf/lib/python3.10/tempfile.py:833: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/var/folders/ct/flqdpp9573b3drcbvfhj15gr0000gn/T/tmp3sk0cv14'>\n",
      "  _warnings.warn(warn_message, ResourceWarning)\n",
      "Processing Audio Files: 100%|██████████| 3/3 [00:38<00:00, 12.69s/it]\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "results = []\n",
    "\n",
    "for file in tqdm(input_files, desc=\"Processing Audio Files\"):\n",
    "    result = embed(file)\n",
    "    results.append(result)\n",
    "\n",
    "total_time = time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fdbeb4-0a63-475f-bdf5-2bc8b299f0a0",
   "metadata": {},
   "source": [
    "## Check completion\n",
    "\n",
    "Finally, check which files were embedded and the overall processing time, along with a preview of the outcome statuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa2123f9-c48c-4f15-a463-3bf84df397e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed!\n",
      "Total time: 38.07 seconds.\n",
      "\n",
      "                           file   status\n",
      "0  sample_audio/test_dset_2.wav  Success\n",
      "1  sample_audio/test_dset_3.wav  Success\n",
      "2  sample_audio/test_dset_1.wav  Success\n"
     ]
    }
   ],
   "source": [
    "# Set up DataFrame for easy previewing\n",
    "status_df = pd.DataFrame(results, columns=[\"file\", \"status\"])\n",
    "print(\"Processing completed!\")\n",
    "print(f\"Total time: {total_time:.2f} seconds.\\n\")\n",
    "print(status_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24c2ee-3a02-48d6-af85-ebb0ff2f749e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opso11_tf",
   "language": "python",
   "name": "opso11_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
